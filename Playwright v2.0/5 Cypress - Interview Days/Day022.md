# Day 22: Performance Testing, Load Testing & Advanced Metrics

**Date:** Day 22 of 25  
**Duration:** 8 hours  
**Difficulty:** Advanced  
**Focus Area:** Performance Testing Fundamentals, Load Testing with K6, Apache JMeter, Continuous Performance Testing, SLA Monitoring, Advanced Metrics & Reporting

---

## ğŸ¯ **Learning Objectives**

By the end of Day 22, you will:

âœ… Understand performance testing fundamentals and metrics  
âœ… Master K6 framework for load testing  
âœ… Build load test scenarios with realistic user behavior  
âœ… Implement Apache JMeter for complex testing scenarios  
âœ… Configure continuous performance testing in CI/CD  
âœ… Establish SLA thresholds and monitoring  
âœ… Analyze performance test results and identify bottlenecks  
âœ… Implement distributed load testing strategies  
âœ… Create custom performance metrics and reporting  
âœ… Integrate performance testing into automation pipelines  

---

## â° **Daily Schedule (8 Hours)**

| Time | Activity | Duration |
|------|----------|----------|
| 8:00 - 8:30 | Review Day 21 & Performance Testing Introduction | 30 min |
| 8:30 - 10:30 | **Theory Session 1:** Performance Metrics & K6 Fundamentals | 2 hours |
| 10:30 - 11:00 | Break | 30 min |
| 11:00 - 1:00 PM | **Hands-On Lab 1:** K6 Load Testing Implementation | 2 hours |
| 1:00 - 2:00 PM | Lunch break | 1 hour |
| 2:00 - 4:00 PM | **Theory Session 2:** JMeter & Advanced Load Testing Patterns | 2 hours |
| 4:00 - 4:30 PM | Break | 30 min |
| 4:30 - 6:30 PM | **Hands-On Lab 2:** Continuous Performance Testing Pipeline | 2 hours |

---

## ğŸ“š **THEORY SESSION 1: Performance Metrics & K6 Fundamentals (2 hours)**

### **Part 22.1: Performance Testing Fundamentals**

#### **Types of Performance Testing**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PERFORMANCE TESTING TYPES                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ 1. LOAD TEST                                        â”‚
â”‚    How does system behave under expected load?     â”‚
â”‚    Simulate: Expected concurrent users             â”‚
â”‚    Measure: Response times, throughput, resources  â”‚
â”‚                                                     â”‚
â”‚ 2. STRESS TEST                                      â”‚
â”‚    What's the breaking point?                      â”‚
â”‚    Simulate: Gradual increase beyond normal load   â”‚
â”‚    Measure: When/where system fails, degradation  â”‚
â”‚                                                     â”‚
â”‚ 3. SPIKE TEST                                       â”‚
â”‚    How does system handle sudden traffic surge?    â”‚
â”‚    Simulate: Sudden jump in users                  â”‚
â”‚    Measure: Recovery time, error rate              â”‚
â”‚                                                     â”‚
â”‚ 4. ENDURANCE TEST                                   â”‚
â”‚    Can system handle load over extended period?    â”‚
â”‚    Simulate: Constant load for hours/days          â”‚
â”‚    Measure: Memory leaks, degradation over time   â”‚
â”‚                                                     â”‚
â”‚ 5. SOAK TEST                                        â”‚
â”‚    Does system maintain performance under sustained load? â”‚
â”‚    Simulate: Moderate load for extended time      â”‚
â”‚    Measure: Performance drift, resource leaks      â”‚
â”‚                                                     â”‚
â”‚ 6. CAPACITY TEST                                    â”‚
â”‚    What's the maximum capacity?                    â”‚
â”‚    Simulate: Increase load until failure           â”‚
â”‚    Measure: Max concurrent users, throughput      â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Key Performance Metrics**

| Metric | Description | Benchmark | Interpretation |
|--------|-------------|-----------|-----------------|
| **Response Time** | Time from request to response | < 2 sec | User wait time |
| **Throughput** | Requests completed per second | > 100 req/s | System capacity |
| **Error Rate** | % of failed requests | < 0.1% | System reliability |
| **Latency (p95/p99)** | Time for 95%/99% of requests | p95 < 3s | Tail latencies |
| **CPU Usage** | Processor utilization | < 75% | Resource constraint |
| **Memory Usage** | RAM consumption | < 80% | Memory constraint |
| **Concurrent Users** | Simultaneous users | Product-specific | Load capacity |
| **Requests/sec (RPS)** | Throughput metric | Product-specific | Capacity metric |
| **Connections** | Active TCP connections | Product-specific | Resource tracking |
| **Database Queries** | DB operations/sec | Product-specific | Backend bottleneck |

#### **SLA Definition Example**

```
Service Level Agreement (SLA):

1. AVAILABILITY
   â””â”€ 99.9% uptime (< 43.2 minutes downtime/month)

2. PERFORMANCE
   â”œâ”€ P50 response time: < 200ms
   â”œâ”€ P95 response time: < 500ms
   â”œâ”€ P99 response time: < 1000ms
   â””â”€ P99.9 response time: < 2000ms

3. ERROR RATE
   â””â”€ < 0.1% (1 error per 1000 requests)

4. THROUGHPUT
   â””â”€ Support minimum 1000 concurrent users

5. DATA CONSISTENCY
   â””â”€ 100% ACID compliance
```

### **Part 22.2: K6 Framework Introduction**

#### **What is K6?**

K6 is a modern load testing tool built for developers. It uses JavaScript (ES6+) for test scripts.

**K6 Advantages:**
- âœ… JavaScript-based (familiar to QA engineers)
- âœ… Cloud execution support (k6 Cloud)
- âœ… Protocol-specific APIs (HTTP, WebSocket, gRPC)
- âœ… Built-in metrics and real-time feedback
- âœ… Easy integration with CI/CD
- âœ… Low memory footprint
- âœ… Open source and free

#### **K6 Installation**

```bash
# macOS
brew install k6

# Linux (Ubuntu/Debian)
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 \
  --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
echo "deb https://dl.k6.io/deb stable main" | \
  sudo tee /etc/apt/sources.list.d/k6.list
sudo apt-get update
sudo apt-get install k6

# Windows (via Chocolatey)
choco install k6

# Docker
docker run -i grafana/k6 run - < script.js

# Verify installation
k6 version
```

#### **Basic K6 Script Structure**

```javascript
import http from 'k6/http';
import { check, group } from 'k6';
import { Rate, Trend, Counter, Gauge } from 'k6/metrics';

// Custom metrics
let errorRate = new Rate('errors');
let responseTime = new Trend('response_time');
let successCounter = new Counter('success_count');
let concurrentUsers = new Gauge('concurrent_users');

// Configure test scenarios
export const options = {
  stages: [
    { duration: '2m', target: 100 },  // Ramp up to 100 users
    { duration: '5m', target: 100 },  // Stay at 100 users
    { duration: '2m', target: 0 },    // Ramp down
  ],
  thresholds: {
    http_req_duration: ['p(95)<500', 'p(99)<1000'],  // 95% < 500ms
    http_req_failed: ['rate<0.1'],                   // Error rate < 0.1%
  },
};

// Test execution
export default function () {
  group('API Requests', () => {
    // GET request
    let response = http.get('http://localhost:3000/api/users');
    
    check(response, {
      'status is 200': (r) => r.status === 200,
      'response time < 500ms': (r) => r.timings.duration < 500,
    }) || errorRate.add(1);
    
    // Track metrics
    responseTime.add(response.timings.duration);
    successCounter.add(1);
    concurrentUsers.add(1);
  });
}
```

#### **K6 Execution Modes**

```javascript
// 1. SIMPLE LOAD TEST
export const options = {
  vus: 10,          // 10 virtual users
  duration: '30s',  // For 30 seconds
};

// 2. RAMPING LOAD TEST
export const options = {
  stages: [
    { duration: '1m', target: 10 },
    { duration: '5m', target: 50 },
    { duration: '2m', target: 100 },
    { duration: '5m', target: 100 },
    { duration: '2m', target: 50 },
    { duration: '1m', target: 0 },
  ],
};

// 3. SPIKE TEST
export const options = {
  stages: [
    { duration: '2m', target: 10 },
    { duration: '1m', target: 100 },  // Spike!
    { duration: '2m', target: 10 },
    { duration: '1m', target: 1000 }, // Big spike!
    { duration: '5m', target: 10 },
  ],
};

// 4. SOAK TEST
export const options = {
  stages: [
    { duration: '5m', target: 50 },
    { duration: '8h', target: 50 },   // 8 hours at constant load
    { duration: '5m', target: 0 },
  ],
};

// 5. STRESS TEST
export const options = {
  stages: [
    { duration: '2m', target: 100 },
    { duration: '2m', target: 200 },
    { duration: '2m', target: 300 },
    { duration: '2m', target: 400 },
    { duration: '2m', target: 500 },
    { duration: '2m', target: 0 },
  ],
};
```

### **Part 22.3: K6 HTTP Module & Assertions**

#### **HTTP Methods in K6**

```javascript
import http from 'k6/http';
import { check } from 'k6';

// GET request
let res = http.get('http://api.example.com/users');

// POST request
let res = http.post('http://api.example.com/users', 
  JSON.stringify({
    name: 'John Doe',
    email: 'john@example.com'
  }),
  { headers: { 'Content-Type': 'application/json' } }
);

// PUT request
let res = http.put('http://api.example.com/users/1',
  JSON.stringify({ name: 'Jane Doe' })
);

// DELETE request
let res = http.del('http://api.example.com/users/1');

// PATCH request
let res = http.patch('http://api.example.com/users/1',
  JSON.stringify({ status: 'active' })
);

// With authentication
let res = http.get('http://api.example.com/users', {
  headers: {
    'Authorization': 'Bearer token123',
    'User-Agent': 'k6/v0.0.1'
  },
  cookies: { sessionid: 'abc123' }
});
```

#### **Response Object Properties**

```javascript
let response = http.get('http://api.example.com/users');

// Status information
console.log(response.status);           // 200
console.log(response.statusText);       // 'OK'

// Headers
console.log(response.headers);          // Object with all headers
console.log(response.headers['content-type']);

// Body
console.log(response.body);             // Response body as string
console.log(response.json());           // Parsed JSON

// Timing information
console.log(response.timings);
// {
//   blocked: 5,
//   connecting: 10,
//   tls_handshaking: 15,
//   sending: 20,
//   waiting: 100,
//   receiving: 50,
//   duration: 200
// }

// Cookies
console.log(response.cookies);
```

#### **Check and Assertions**

```javascript
import { check } from 'k6';

let response = http.get('http://api.example.com/users/1');

// Simple checks
check(response, {
  'status is 200': (r) => r.status === 200,
  'has user data': (r) => r.json().name !== undefined,
  'response time < 500ms': (r) => r.timings.duration < 500,
});

// Complex checks
check(response, {
  'has correct user': (r) => {
    let user = r.json();
    return user.id === 1 && user.email.includes('@');
  },
  'response headers valid': (r) => {
    return r.headers['content-type'].includes('application/json') &&
           r.headers['x-custom-header'] === 'expected-value';
  },
});

// Check with fail handling
let passed = check(response, {
  'status is 200': (r) => r.status === 200
});

if (!passed) {
  console.error('Test failed! Response:', response.body);
}
```

### **Part 22.4: K6 Metrics & Thresholds**

#### **Built-in Metrics**

```
HTTP Metrics:
â”œâ”€ http_req_duration          Response time (ms)
â”œâ”€ http_req_blocked           Time waiting for connection
â”œâ”€ http_req_connecting        TCP connection time
â”œâ”€ http_req_tls_handshaking   TLS handshake time
â”œâ”€ http_req_sending           Time sending request
â”œâ”€ http_req_waiting           Time waiting for response
â”œâ”€ http_req_receiving         Time receiving response
â”œâ”€ http_req_failed            Boolean: request failed
â”œâ”€ http_reqs                  Total requests count
â””â”€ http_connections           Active connections

VU Metrics:
â”œâ”€ vus                        Current virtual users
â”œâ”€ vus_max                    Max virtual users
â””â”€ vu_iterations              Completed iterations per VU

GRPC Metrics:
â””â”€ grpc_*                     gRPC-specific metrics

WebSocket Metrics:
â””â”€ ws_*                       WebSocket-specific metrics
```

#### **Custom Metrics**

```javascript
import { 
  Trend, 
  Rate, 
  Counter, 
  Gauge 
} from 'k6/metrics';

// TREND: Track distribution of values (min, max, avg, p95, p99)
let responseTime = new Trend('response_time');
responseTime.add(123);  // Add data point
responseTime.add(456);

// RATE: Track percentage of truthy values
let errorRate = new Rate('error_rate');
errorRate.add(response.status !== 200);  // Add boolean

// COUNTER: Track sum of values
let totalRequests = new Counter('total_requests');
totalRequests.add(1);

// GAUGE: Track latest value (last write wins)
let activeConnections = new Gauge('active_connections');
activeConnections.set(42);

// Usage in script
export default function () {
  let response = http.get('http://api.example.com/data');
  
  responseTime.add(response.timings.duration);
  errorRate.add(response.status !== 200);
  totalRequests.add(1);
  activeConnections.set(context.concurrentVUs);
}
```

#### **Threshold Configuration**

```javascript
export const options = {
  stages: [
    { duration: '1m', target: 50 },
    { duration: '5m', target: 50 },
    { duration: '1m', target: 0 },
  ],
  
  // Define SLA thresholds
  thresholds: {
    // 95% of requests must be under 500ms
    'http_req_duration': ['p(95)<500'],
    
    // 99% of requests must be under 1000ms
    'http_req_duration': ['p(99)<1000'],
    
    // Error rate must be < 0.1%
    'http_req_failed': ['rate<0.001'],
    
    // Custom metric threshold
    'custom_metric': ['p(95)<100', 'p(99)<200'],
    
    // Multiple conditions
    'http_req_duration': [
      'p(95)<500',
      'p(99)<1000',
      'max<2000'
    ],
  },
};
```

---

## ğŸ’» **HANDS-ON LAB 1: K6 Load Testing Implementation (2 hours)**

### **Exercise 22.1: Setup K6 Project**

#### **Step 1: Create K6 Project Structure**

```bash
mkdir k6-load-testing && cd k6-load-testing

# Create directory structure
mkdir -p {scripts,tests,reports,config,data}

# Initialize package.json
npm init -y

# Install k6 (if not installed globally)
npm install --save-dev k6

# For additional tools
npm install --save-dev @k6/faker
```

#### **Step 2: Create Basic Load Test**

**scripts/basic-load-test.js:**

```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Trend, Rate, Counter, Gauge } from 'k6/metrics';

// Define custom metrics
const responseTime = new Trend('response_time');
const errorRate = new Rate('error_rate');
const successCount = new Counter('success_count');
const concurrentVUs = new Gauge('concurrent_vus');

// Configuration
export const options = {
  stages: [
    { duration: '10s', target: 5 },    // Ramp up to 5 users
    { duration: '30s', target: 10 },   // Ramp up to 10 users
    { duration: '20s', target: 10 },   // Stay at 10 users
    { duration: '10s', target: 0 },    // Ramp down
  ],
  thresholds: {
    'http_req_duration': ['p(95)<500', 'p(99)<1000'],
    'http_req_failed': ['rate<0.1'],
    'error_rate': ['rate<0.1'],
  },
};

// Test logic
export default function () {
  // Track concurrent VUs
  concurrentVUs.set(__VU);
  
  // Test 1: GET users list
  let response = http.get('http://localhost:3001/api/users');
  
  // Check response
  let success = check(response, {
    'GET /api/users status 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
    'has users data': (r) => r.json().users !== undefined,
  });
  
  // Track metrics
  responseTime.add(response.timings.duration);
  errorRate.add(!success);
  if (success) successCount.add(1);
  
  // Random sleep between requests
  sleep(Math.random() * 2);
  
  // Test 2: GET specific user
  response = http.get('http://localhost:3001/api/users/1');
  
  check(response, {
    'GET /api/users/:id status 200': (r) => r.status === 200,
    'user has required fields': (r) => {
      let user = r.json();
      return user.id && user.name && user.email;
    },
  });
  
  responseTime.add(response.timings.duration);
  errorRate.add(response.status !== 200);
  
  sleep(Math.random() * 2);
  
  // Test 3: POST create user
  response = http.post('http://localhost:3001/api/users',
    JSON.stringify({
      name: `Test User ${__VU}`,
      email: `user${__VU}@example.com`,
      role: 'user'
    }),
    { headers: { 'Content-Type': 'application/json' } }
  );
  
  check(response, {
    'POST /api/users status 201': (r) => r.status === 201,
    'new user has id': (r) => r.json().id !== undefined,
  });
  
  responseTime.add(response.timings.duration);
  errorRate.add(response.status !== 201);
  
  sleep(Math.random() * 2);
}
```

#### **Step 3: Run K6 Test**

```bash
# Run basic load test
k6 run scripts/basic-load-test.js

# Run with verbose output
k6 run -v scripts/basic-load-test.js

# Run with custom VU and duration
k6 run --vus 10 --duration 1m scripts/basic-load-test.js

# Run with local web dashboard
k6 run --out web scripts/basic-load-test.js
```

#### **Expected Output:**

```
     data_received..................: 45 kB 75.0 B/s
     data_sent.......................: 42 kB 70.0 B/s
     http_req_blocked...............: avg=10.5ms   min=0s    med=8.5ms  max=25.4ms  p(90)=21.2ms p(95)=23.1ms
     http_req_connecting............: avg=8.2ms    min=0s    med=6.8ms  max=20.3ms p(90)=18.2ms p(95)=19.8ms
     http_req_duration..............: avg=42.5ms   min=20ms  med=38ms   max=120ms  p(90)=65ms   p(95)=78ms
     http_req_failed................: 0.00%
     http_req_receiving.............: avg=1.2ms    min=0s    med=1ms    max=10ms   p(90)=2ms    p(95)=2ms
     http_req_sending...............: avg=2.1ms    min=0s    med=2ms    max=8ms    p(90)=3ms    p(95)=3ms
     http_req_tls_handshaking.......: avg=0s       min=0s    med=0s     max=0s     p(90)=0s     p(95)=0s
     http_req_waiting...............: avg=39.2ms   min=18ms  med=35ms   max=110ms  p(90)=62ms   p(95)=75ms
     http_reqs......................: 142 236.667/s
     iteration_duration.............: avg=6.42s    min=6s    med=6.2s   max=7.1s   p(90)=6.8s   p(95)=6.9s
     iterations.....................: 24 40.0/iter
     vus............................: 0
     vus_max........................: 10
âœ“ PASSED (5 out of 5 thresholds met)
```

### **Exercise 22.2: Advanced Load Test with Scenarios**

**scripts/advanced-load-test.js:**

```javascript
import http from 'k6/http';
import { check, group, sleep } from 'k6';
import { Trend, Rate, Counter } from 'k6/metrics';

const apiResponseTime = new Trend('api_response_time');
const apiErrorRate = new Rate('api_error_rate');
const apiRequests = new Counter('api_requests');

export const options = {
  scenarios: {
    // Scenario 1: Normal traffic
    normal_load: {
      executor: 'ramping-vus',
      startVUs: 0,
      stages: [
        { duration: '1m', target: 20 },
        { duration: '3m', target: 20 },
        { duration: '1m', target: 0 },
      ],
      gracefulStop: '30s',
    },
    
    // Scenario 2: Spike test (runs concurrently)
    spike_test: {
      executor: 'ramping-vus',
      startVUs: 0,
      stages: [
        { duration: '1m', target: 0 },
        { duration: '30s', target: 100 },  // Spike!
        { duration: '1m', target: 0 },
      ],
      gracefulStop: '30s',
    },
  },
  
  thresholds: {
    'api_response_time': ['p(95)<500', 'p(99)<1000'],
    'api_error_rate': ['rate<0.1'],
  },
};

export default function () {
  // Group: User Operations
  group('User Operations', () => {
    // Get all users
    let response = http.get('http://localhost:3001/api/users');
    
    check(response, {
      'GET users - 200': (r) => r.status === 200,
      'GET users - response time': (r) => r.timings.duration < 500,
    });
    
    apiResponseTime.add(response.timings.duration, { endpoint: 'GET /users' });
    apiErrorRate.add(response.status !== 200);
    apiRequests.add(1);
    
    sleep(1);
    
    // Get specific user
    response = http.get('http://localhost:3001/api/users/1');
    
    check(response, {
      'GET user/:id - 200': (r) => r.status === 200,
      'GET user/:id - response time': (r) => r.timings.duration < 300,
    });
    
    apiResponseTime.add(response.timings.duration, { endpoint: 'GET /users/:id' });
    apiErrorRate.add(response.status !== 200);
    apiRequests.add(1);
    
    sleep(1);
  });
  
  // Group: Product Operations
  group('Product Operations', () => {
    let response = http.get('http://localhost:3001/api/products');
    
    check(response, {
      'GET products - 200': (r) => r.status === 200,
    });
    
    apiResponseTime.add(response.timings.duration, { endpoint: 'GET /products' });
    apiErrorRate.add(response.status !== 200);
    apiRequests.add(1);
    
    sleep(1);
    
    // Filter products
    response = http.get('http://localhost:3001/api/products?minPrice=10&maxPrice=100');
    
    check(response, {
      'GET products filtered - 200': (r) => r.status === 200,
      'has products': (r) => r.json().products.length > 0,
    });
    
    apiResponseTime.add(response.timings.duration, { endpoint: 'GET /products?filter' });
    apiErrorRate.add(response.status !== 200);
    apiRequests.add(1);
    
    sleep(1);
  });
  
  // Group: Order Operations
  group('Order Operations', () => {
    let response = http.post('http://localhost:3001/api/orders',
      JSON.stringify({
        userId: 1 + Math.floor(Math.random() * 5),
        items: [
          { productId: 1, qty: 1 },
          { productId: 2, qty: 2 }
        ]
      }),
      { headers: { 'Content-Type': 'application/json' } }
    );
    
    check(response, {
      'POST order - 201': (r) => r.status === 201,
      'order has id': (r) => r.json().id !== undefined,
    });
    
    apiResponseTime.add(response.timings.duration, { endpoint: 'POST /orders' });
    apiErrorRate.add(response.status !== 201);
    apiRequests.add(1);
    
    sleep(1);
  });
}
```

### **Exercise 22.3: Quiz - K6 Performance Testing**

**Question 1:** What is a "soak test"?
- A) Testing with high traffic spike
- B) Testing under constant load for extended time
- C) Testing to find breaking point
- D) Testing error scenarios
**Answer: B** - Soak tests verify sustained performance

**Question 2:** What does P95 response time mean?
- A) 95% of total response time
- B) 95th percentile (95% of requests faster than this)
- C) 95 milliseconds
- D) 95% of users experience this time
**Answer: B** - P95 is the 95th percentile

**Question 3:** How do you define multiple concurrent test scenarios in K6?
- A) Create separate script files
- B) Use scenarios in options
- C) Run K6 multiple times
- D) Use different browsers
**Answer: B** - K6 scenarios run concurrently

**Question 4:** What is the purpose of thresholds in K6?
- A) Limit maximum load
- B) Define pass/fail criteria for SLA
- C) Control test duration
- D) Set response time limits
**Answer: B** - Thresholds define SLA compliance

**Question 5:** Which K6 metric tracks request failures?
- A) http_req_duration
- B) http_req_failed
- C) http_error_count
- D) http_req_status
**Answer: B** - http_req_failed tracks failed requests

---

## ğŸ“š **THEORY SESSION 2: JMeter & Advanced Load Testing Patterns (2 hours)**

### **Part 22.5: Apache JMeter Introduction**

#### **What is JMeter?**

Apache JMeter is an open-source Java-based load testing tool that can test:
- Web applications (HTTP/HTTPS)
- FTP servers
- JDBC databases
- SOAP/REST web services
- LDAP servers
- Message-oriented middleware (JMS)

**JMeter vs K6:**

| Aspect | JMeter | K6 |
|--------|--------|-----|
| **Language** | Java GUI/script | JavaScript |
| **Learning Curve** | Steep | Gentle |
| **Protocol Support** | Extensive | HTTP/WebSocket focus |
| **Cloud Support** | Limited | Built-in (k6 Cloud) |
| **Distributed Testing** | Powerful | Good |
| **Real-time Dashboard** | Limited | Excellent |
| **Scripting** | Complex | Simple |
| **Community** | Large | Growing |
| **Use Case** | Complex enterprise scenarios | Modern APIs |

#### **JMeter Installation**

```bash
# macOS
brew install jmeter

# Linux
sudo apt-get install jmeter

# Windows
# Download from: https://jmeter.apache.org/download_jmeter.cgi
# Extract ZIP and run: bin\jmeter.bat

# Docker
docker run -it --rm -p 4444:4444 justb4/jmeter:latest

# Verify installation
jmeter --version
```

#### **JMeter Components**

```
Test Plan (Root)
â”œâ”€â”€ Thread Group (Simulates users)
â”‚   â”œâ”€â”€ Config Elements
â”‚   â”‚   â”œâ”€â”€ HTTP Request Defaults
â”‚   â”‚   â”œâ”€â”€ CSV Data Set Config
â”‚   â”‚   â””â”€â”€ User Defined Variables
â”‚   â”‚
â”‚   â”œâ”€â”€ Samplers (Actual requests)
â”‚   â”‚   â”œâ”€â”€ HTTP Request
â”‚   â”‚   â”œâ”€â”€ JDBC Request
â”‚   â”‚   â”œâ”€â”€ SOAP Request
â”‚   â”‚   â””â”€â”€ JMS Request
â”‚   â”‚
â”‚   â”œâ”€â”€ Logical Controllers
â”‚   â”‚   â”œâ”€â”€ If Controller
â”‚   â”‚   â”œâ”€â”€ Loop Controller
â”‚   â”‚   â”œâ”€â”€ Once Only Controller
â”‚   â”‚   â””â”€â”€ Switch Controller
â”‚   â”‚
â”‚   â”œâ”€â”€ Pre-processors (Before sampler)
â”‚   â”‚   â”œâ”€â”€ User Parameters
â”‚   â”‚   â”œâ”€â”€ JDBC Pre-processor
â”‚   â”‚   â””â”€â”€ Regular Expression Extractor
â”‚   â”‚
â”‚   â”œâ”€â”€ Post-processors (After sampler)
â”‚   â”‚   â”œâ”€â”€ Regular Expression Extractor
â”‚   â”‚   â”œâ”€â”€ CSS Selector Extractor
â”‚   â”‚   â”œâ”€â”€ JSON Extractor
â”‚   â”‚   â””â”€â”€ JDBC Post-processor
â”‚   â”‚
â”‚   â”œâ”€â”€ Assertions (Validation)
â”‚   â”‚   â”œâ”€â”€ Response Assertion
â”‚   â”‚   â”œâ”€â”€ Duration Assertion
â”‚   â”‚   â”œâ”€â”€ Size Assertion
â”‚   â”‚   â””â”€â”€ HTML Assertion
â”‚   â”‚
â”‚   â””â”€â”€ Listeners (Results)
â”‚       â”œâ”€â”€ View Results Tree
â”‚       â”œâ”€â”€ Graph Results
â”‚       â”œâ”€â”€ Table Results
â”‚       â”œâ”€â”€ Summary Report
â”‚       â””â”€â”€ Backend Listener
```

### **Part 22.6: JMeter Test Plan Structure**

#### **Simple Load Test Structure**

```jmx
<?xml version="1.0" encoding="UTF-8"?>
<jmeterTestPlan version="1.2">
  <hashTree>
    <!-- Test Plan -->
    <TestPlan guiclass="TestPlanGui" testname="API Load Test" enabled="true">
      <elementProp name="TestPlan.user_defined_variables" elementType="Arguments"/>
      <stringProp name="TestPlan.functional_mode">false</stringProp>
      <boolProp name="TestPlan.serialize_threadgroups">false</boolProp>
    </TestPlan>
    <hashTree>
      
      <!-- Thread Group (Simulates users) -->
      <ThreadGroup guiclass="ThreadGroupGui" testname="User Load" enabled="true">
        <elementProp name="ThreadGroup.main_controller" 
                      elementType="LoopController" guiclass="LoopControlPanel">
          <boolProp name="LoopController.continue_forever">false</boolProp>
          <stringProp name="LoopController.loops">1</stringProp>
        </elementProp>
        <stringProp name="ThreadGroup.num_threads">100</stringProp>
        <stringProp name="ThreadGroup.ramp_time">60</stringProp>
        <elementProp name="ThreadGroup.scheduler" 
                      elementType="elementType" guiclass="SchedulerGui">
          <boolProp name="ThreadGroup.scheduler">false</boolProp>
        </elementProp>
      </ThreadGroup>
      <hashTree>
        
        <!-- HTTP Request Defaults -->
        <ConfigTestElement guiclass="HttpDefaultsGui" 
                          testname="HTTP Request Defaults" enabled="true">
          <elementProp name="HTTPsampler.Arguments" elementType="Arguments"/>
          <stringProp name="HTTPSampler.domain">localhost</stringProp>
          <stringProp name="HTTPSampler.port">3001</stringProp>
          <stringProp name="HTTPSampler.protocol">http</stringProp>
        </ConfigTestElement>
        <hashTree/>
        
        <!-- HTTP Request Sampler -->
        <HTTPSamplerProxy guiclass="HttpTestSampleGui" 
                         testname="GET /api/users" enabled="true">
          <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
            <collectionProp name="Arguments.arguments"/>
          </elementProp>
          <stringProp name="HTTPSampler.domain"/>
          <stringProp name="HTTPSampler.port"/>
          <stringProp name="HTTPSampler.protocol">http</stringProp>
          <stringProp name="HTTPSampler.path">/api/users</stringProp>
          <stringProp name="HTTPSampler.method">GET</stringProp>
        </HTTPSamplerProxy>
        <hashTree/>
        
        <!-- Response Assertions -->
        <ResponseAssertion guiclass="AssertionGui" 
                          testname="Response Assertion" enabled="true">
          <collectionProp name="Asserion.test_strings">
            <stringProp name="49586">200</stringProp>
          </collectionProp>
          <stringProp name="Assertion.test_type">1</stringProp>
          <boolProp name="Assertion.assume_success">false</boolProp>
        </ResponseAssertion>
        <hashTree/>
        
        <!-- Summary Report -->
        <ResultCollector guiclass="TableVisualizer" 
                        testname="View Results Table" enabled="true">
          <boolProp name="ResultCollector.error_logging">false</boolProp>
          <objProp>
            <name>samplers</name>
            <value class="SampleSaveConfiguration">
              <time>true</time>
              <latency>true</latency>
              <timestamp>true</timestamp>
              <success>true</success>
              <label>true</label>
              <code>true</code>
              <message>true</message>
              <threadName>true</threadName>
              <responseData>false</responseData>
              <responseFile>false</responseFile>
              <samplerData>false</samplerData>
              <dataType>true</dataType>
              <encoding>false</encoding>
              <assertions>true</assertions>
              <subresults>true</subresults>
              <responseHeaders>false</responseHeaders>
              <requestHeaders>false</requestHeaders>
              <responseDataOnError>false</responseDataOnError>
              <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>
              <assertionsResultsToSave>0</assertionsResultsToSave>
              <bytes>true</bytes>
              <threadCounts>true</threadCounts>
            </value>
          </objProp>
          <stringProp name="filename"></stringProp>
        </ResultCollector>
        <hashTree/>
        
      </hashTree>
    </hashTree>
  </hashTree>
</jmeterTestPlan>
```

### **Part 22.7: Continuous Performance Testing**

#### **Integration with CI/CD Pipeline**

```yaml
# .github/workflows/performance-test.yml
name: Performance Tests

on:
  push:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

jobs:
  performance-test:
    runs-on: ubuntu-latest
    
    services:
      mock-server:
        image: node:18
        options: >-
          --health-cmd="curl -f http://localhost:3001/health || exit 1"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Install K6
        run: |
          sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 \
            --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb https://dl.k6.io/deb stable main" | \
            sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6
      
      - name: Start Mock Server
        run: |
          npm install
          node mock-server/index.js &
          sleep 2
      
      - name: Run Load Test
        run: k6 run --vus 10 --duration 1m scripts/load-test.js \
          --out json=results.json
      
      - name: Upload Results
        uses: actions/upload-artifact@v3
        with:
          name: load-test-results
          path: results.json
      
      - name: Check Thresholds
        run: |
          # Parse results and check thresholds
          node scripts/check-thresholds.js results.json
      
      - name: Publish Report
        if: always()
        run: |
          # Generate and publish report
          node scripts/generate-report.js results.json
```

#### **SLA Monitoring Script**

```javascript
// scripts/check-thresholds.js
const fs = require('fs');
const results = JSON.parse(fs.readFileSync('results.json', 'utf8'));

const thresholds = {
  'p95_response_time': 500,  // 500ms
  'p99_response_time': 1000, // 1000ms
  'error_rate': 0.001,       // 0.1%
  'availability': 0.999      // 99.9%
};

let passed = true;
const issues = [];

// Check P95
const p95 = results.metrics['http_req_duration']['p95'];
if (p95 > thresholds.p95_response_time) {
  passed = false;
  issues.push(`P95 response time ${p95}ms exceeds threshold ${thresholds.p95_response_time}ms`);
}

// Check P99
const p99 = results.metrics['http_req_duration']['p99'];
if (p99 > thresholds.p99_response_time) {
  passed = false;
  issues.push(`P99 response time ${p99}ms exceeds threshold ${thresholds.p99_response_time}ms`);
}

// Check error rate
const errorRate = results.metrics['http_req_failed']['rate'];
if (errorRate > thresholds.error_rate) {
  passed = false;
  issues.push(`Error rate ${errorRate} exceeds threshold ${thresholds.error_rate}`);
}

if (!passed) {
  console.error('âŒ SLA Threshold Violations:');
  issues.forEach(issue => console.error(`   - ${issue}`));
  process.exit(1);
} else {
  console.log('âœ… All SLA thresholds passed!');
}
```

---

## ğŸ’» **HANDS-ON LAB 2: Continuous Performance Testing Pipeline (2 hours)**

### **Exercise 22.4: Build Performance Testing Pipeline**

#### **Step 1: Create K6 Load Test Scripts**

**scripts/performance-test.js:**

```javascript
import http from 'k6/http';
import { check, sleep, group } from 'k6';
import { Trend, Rate, Counter, Gauge } from 'k6/metrics';

// Metrics
const apiDuration = new Trend('api_duration');
const apiErrors = new Rate('api_errors');
const requestsPerSec = new Counter('requests_per_sec');
const concurrentUsers = new Gauge('concurrent_users');

export const options = {
  stages: [
    { duration: '30s', target: 10 },   // Ramp up to 10 users
    { duration: '1m30s', target: 10 }, // Stay at 10 users
    { duration: '30s', target: 0 },    // Ramp down
  ],
  
  thresholds: {
    'api_duration': [
      'p(95)<500',
      'p(99)<1000',
      'max<2000'
    ],
    'api_errors': ['rate<0.01'],
    'http_req_failed': ['rate<0.01'],
  },
  
  ext: {
    loadimpact: {
      projectID: 3456789,
      name: 'Performance Tests'
    }
  }
};

// Test execution
export default function () {
  concurrentUsers.set(__VU);
  
  group('API Performance Suite', () => {
    // Endpoint 1: Get Users
    let res = http.get('http://localhost:3001/api/users');
    apiDuration.add(res.timings.duration, { endpoint: 'GET_users' });
    apiErrors.add(res.status !== 200);
    requestsPerSec.add(1);
    
    check(res, {
      'status 200': (r) => r.status === 200,
      'response time < 300ms': (r) => r.timings.duration < 300,
    });
    
    sleep(1);
    
    // Endpoint 2: Get Products
    res = http.get('http://localhost:3001/api/products?minPrice=10&maxPrice=500');
    apiDuration.add(res.timings.duration, { endpoint: 'GET_products' });
    apiErrors.add(res.status !== 200);
    requestsPerSec.add(1);
    
    check(res, {
      'status 200': (r) => r.status === 200,
      'has products': (r) => r.json().products.length > 0,
    });
    
    sleep(1);
    
    // Endpoint 3: Create Order (POST)
    res = http.post('http://localhost:3001/api/orders',
      JSON.stringify({
        userId: 1 + Math.floor(Math.random() * 2),
        items: [
          { productId: 1, qty: Math.floor(Math.random() * 5) + 1 },
          { productId: 2, qty: Math.floor(Math.random() * 3) + 1 }
        ]
      }),
      { headers: { 'Content-Type': 'application/json' } }
    );
    apiDuration.add(res.timings.duration, { endpoint: 'POST_orders' });
    apiErrors.add(res.status !== 201 && res.status !== 201);
    requestsPerSec.add(1);
    
    check(res, {
      'status 201': (r) => r.status === 201,
      'order created': (r) => r.json().id !== undefined,
    });
    
    sleep(1);
  });
}
```

#### **Step 2: Create Test Report Generator**

**scripts/generate-report.js:**

```javascript
const fs = require('fs');
const path = require('path');

function generateReport(resultsFile) {
  try {
    const rawData = fs.readFileSync(resultsFile);
    const results = JSON.parse(rawData);
    
    const report = {
      timestamp: new Date().toISOString(),
      summary: {
        total_requests: results.metrics?.['http_reqs']?.value || 0,
        failed_requests: results.metrics?.['http_req_failed']?.value || 0,
        error_rate: results.metrics?.['http_req_failed']?.rate || 0,
      },
      response_times: {
        min: results.metrics?.['http_req_duration']?.min || 0,
        max: results.metrics?.['http_req_duration']?.max || 0,
        avg: results.metrics?.['http_req_duration']?.avg || 0,
        p50: results.metrics?.['http_req_duration']?.p50 || 0,
        p95: results.metrics?.['http_req_duration']?.p95 || 0,
        p99: results.metrics?.['http_req_duration']?.p99 || 0,
      },
      throughput: {
        requests_per_sec: results.metrics?.['http_reqs']?.rate || 0,
      },
      status_codes: results.metrics?.['http_resp_code']?.counts || {},
      custom_metrics: {
        api_duration: results.metrics?.['api_duration'] || {},
        api_errors: results.metrics?.['api_errors'] || {},
      }
    };
    
    // Write HTML report
    const html = generateHTML(report);
    fs.writeFileSync('reports/performance-report.html', html);
    
    // Write JSON report
    fs.writeFileSync('reports/performance-report.json', JSON.stringify(report, null, 2));
    
    console.log('âœ… Reports generated:');
    console.log('   - reports/performance-report.html');
    console.log('   - reports/performance-report.json');
    
    return report;
  } catch (error) {
    console.error('Error generating report:', error);
    process.exit(1);
  }
}

function generateHTML(report) {
  return `
<!DOCTYPE html>
<html>
<head>
  <title>Performance Test Report</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    .summary { background: #f0f0f0; padding: 10px; border-radius: 5px; }
    .metrics { display: grid; grid-template-columns: repeat(3, 1fr); gap: 20px; margin: 20px 0; }
    .metric { background: #fff; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
    .metric h3 { margin-top: 0; }
    .metric-value { font-size: 24px; font-weight: bold; color: #0066cc; }
    table { width: 100%; border-collapse: collapse; }
    th, td { border: 1px solid #ddd; padding: 10px; text-align: left; }
    th { background: #333; color: white; }
    .pass { color: green; }
    .fail { color: red; }
  </style>
</head>
<body>
  <h1>Performance Test Report</h1>
  <p>Generated: ${report.timestamp}</p>
  
  <div class="summary">
    <h2>Test Summary</h2>
    <ul>
      <li>Total Requests: ${report.summary.total_requests}</li>
      <li>Failed Requests: ${report.summary.failed_requests}</li>
      <li>Error Rate: ${(report.summary.error_rate * 100).toFixed(2)}%</li>
    </ul>
  </div>
  
  <h2>Response Times</h2>
  <div class="metrics">
    <div class="metric">
      <h3>Minimum</h3>
      <div class="metric-value">${report.response_times.min.toFixed(2)}ms</div>
    </div>
    <div class="metric">
      <h3>Average</h3>
      <div class="metric-value">${report.response_times.avg.toFixed(2)}ms</div>
    </div>
    <div class="metric">
      <h3>Maximum</h3>
      <div class="metric-value">${report.response_times.max.toFixed(2)}ms</div>
    </div>
    <div class="metric">
      <h3>P95</h3>
      <div class="metric-value">${report.response_times.p95.toFixed(2)}ms</div>
    </div>
    <div class="metric">
      <h3>P99</h3>
      <div class="metric-value">${report.response_times.p99.toFixed(2)}ms</div>
    </div>
    <div class="metric">
      <h3>Throughput</h3>
      <div class="metric-value">${report.throughput.requests_per_sec.toFixed(2)}</div>
      <p>req/sec</p>
    </div>
  </div>
  
  <h2>Status Codes</h2>
  <table>
    <tr>
      <th>Status Code</th>
      <th>Count</th>
    </tr>
    ${Object.entries(report.status_codes).map(([code, count]) => 
      `<tr><td>${code}</td><td>${count}</td></tr>`
    ).join('')}
  </table>
</body>
</html>
  `;
}

// Run report generation
if (process.argv[2]) {
  generateReport(process.argv[2]);
}

module.exports = { generateReport };
```

#### **Step 3: Create GitHub Actions Workflow**

**.github/workflows/perf-test.yml:**

```yaml
name: Performance Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'

jobs:
  performance-test:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install K6
        run: |
          sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 \
            --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb https://dl.k6.io/deb stable main" | \
            sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6
      
      - name: Start Services
        run: |
          npm install
          node mock-server/index.js > /tmp/server.log 2>&1 &
          sleep 3
      
      - name: Run Performance Test
        run: |
          k6 run \
            --vus 10 \
            --duration 2m \
            --out json=results.json \
            scripts/performance-test.js
      
      - name: Generate Report
        if: always()
        run: node scripts/generate-report.js results.json
      
      - name: Check Thresholds
        run: node scripts/check-thresholds.js results.json
      
      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: performance-results
          path: reports/
      
      - name: Comment PR with Results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = JSON.parse(fs.readFileSync('reports/performance-report.json'));
            
            const comment = `## Performance Test Results
            
- **Total Requests**: ${report.summary.total_requests}
- **Error Rate**: ${(report.summary.error_rate * 100).toFixed(2)}%
- **Avg Response Time**: ${report.response_times.avg.toFixed(2)}ms
- **P95 Response Time**: ${report.response_times.p95.toFixed(2)}ms
- **P99 Response Time**: ${report.response_times.p99.toFixed(2)}ms
- **Throughput**: ${report.throughput.requests_per_sec.toFixed(2)} req/sec
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
```

### **Exercise 22.5: Quiz - Advanced Load Testing**

**Question 1:** What is a stress test in load testing?
- A) Test normal expected load
- B) Gradually increase load beyond normal until failure
- C) Test sudden traffic spike
- D) Test constant load for hours
**Answer: B** - Stress testing finds breaking point

**Question 2:** What does P99 latency mean in SLA?
- A) 99 milliseconds
- B) 99th percentile (99% of requests faster)
- C) 99% of users wait this time
- D) Error occurs in 99% of cases
**Answer: B** - P99 is 99th percentile metric

**Question 3:** Which tool is better for modern API testing?
- A) Apache JMeter
- B) K6
- C) Both equally
- D) LoadRunner
**Answer: B** - K6 is built for modern APIs

**Question 4:** What should continuous performance tests track?
- A) Only response time
- B) Throughput, response time, error rate, resource usage
- C) Only error rate
- D) Database queries only
**Answer: B** - Comprehensive metric tracking

**Question 5:** How do you fail a performance test in K6?
- A) When any request fails
- B) By defining thresholds and not meeting them
- C) After specific duration
- D) When throughput decreases
**Answer: B** - Thresholds define pass/fail criteria

---

## ğŸ¯ **Mini-Project 22.1: Enterprise Performance Testing Suite**

### **Requirements**

Build a comprehensive performance testing solution:

1. **K6 Load Tests**
   - Load test (normal traffic)
   - Spike test (sudden surge)
   - Soak test (extended duration)
   - Stress test (until failure)

2. **JMeter Scenarios**
   - Complex user workflows
   - Database queries
   - Multi-step transactions

3. **CI/CD Integration**
   - Automated performance tests
   - Threshold checks
   - Report generation
   - SLA monitoring

4. **Metrics & Reporting**
   - Custom metrics
   - HTML reports
   - JSON results export
   - Trend analysis

5. **Documentation**
   - Test plan documentation
   - Results interpretation guide
   - Tuning recommendations
   - Baseline metrics

---

## ğŸ“‹ **Daily Checklist - Day 22**

- [ ] Reviewed Day 21 integration testing
- [ ] Understood performance testing types
- [ ] Completed Theory Session 1
- [ ] Learned K6 fundamentals
- [ ] Installed and verified K6
- [ ] Created basic load test
- [ ] Completed Exercise 22.1
- [ ] Built advanced K6 scenarios
- [ ] Configured SLA thresholds
- [ ] Completed Theory Session 2
- [ ] Learned JMeter basics
- [ ] Understood JMeter architecture
- [ ] Created performance test pipeline
- [ ] Implemented report generation
- [ ] Set up GitHub Actions workflow
- [ ] Completed Exercise 22.4
- [ ] Tested performance metrics
- [ ] Answered all quiz questions (5/5)
- [ ] Built Mini-Project 22.1
- [ ] Created comprehensive reporting

**Daily Metrics:**
- Quiz Score: ___/5
- Load tests created: ___ count
- Endpoints tested: ___ count
- SLA thresholds defined: ___ count
- Reports generated: ___ count
- Confidence Level (1-5): ___
- Time Spent: ___ hours

---

## ğŸ§  **Key Concepts Summary**

**Performance Testing Types:**
1. Load: Expected traffic behavior
2. Stress: Breaking point identification
3. Spike: Sudden surge handling
4. Soak: Extended duration resilience
5. Capacity: Maximum throughput

**Key Metrics:**
- Response time (min, max, avg, P95, P99)
- Throughput (requests/sec)
- Error rate (%)
- Resource usage (CPU, Memory)
- Concurrent users

**K6 Advantages:**
- JavaScript-based (easy to learn)
- Cloud execution support
- Real-time metrics
- CI/CD friendly
- Open source

**Best Practices:**
1. Define SLA before testing
2. Test realistic user behavior
3. Monitor resource usage
4. Analyze bottlenecks
5. Automate in CI/CD
6. Trend analysis over time
7. Load test regularly
8. Test error scenarios

---

## ğŸ”— **Resources for Further Learning**

- [K6 Official Documentation](https://k6.io/docs/)
- [K6 Best Practices](https://k6.io/blog/)
- [Apache JMeter Guide](https://jmeter.apache.org/usermanual/)
- [Performance Testing Guide](https://gtmetrix.com/)
- [Load Testing Strategies](https://www.redline13.com/)

---

## ğŸš€ **Ready for Day 23?**

By completing Day 22, you've mastered:
- âœ… Performance testing fundamentals
- âœ… K6 framework and scripting
- âœ… Load, stress, spike, soak testing
- âœ… SLA definition and monitoring
- âœ… Apache JMeter basics
- âœ… Metrics collection and analysis
- âœ… Continuous performance testing
- âœ… Report generation and dashboards
- âœ… Bottleneck identification
- âœ… CI/CD integration

**Next (Day 23):** Advanced Test Frameworks & System Design for Automation
- Building custom test frameworks
- Design patterns for test automation
- Scalable test architecture
- Cloud testing strategies
- AI/ML in testing

---

## ğŸ“Š **Course Progress**

```
Week 1          Week 2          Week 3          Week 4          Week 5
Foundation      Mastery         API Testing     DevOps/Docker   Integration/Perf
Days 1-5        Days 6-11       Days 12-15      Days 16-20      Days 21-25
âœ… 100%         âœ… 100%         âœ… 100%         âœ… 100%         ğŸ”œ Day 22
                                                                (8%)

Overall: 22/25 Days Complete (88%)
Remaining: 3 Days to Complete (Days 23-25)
```

---

**Congratulations on reaching Day 22!** ğŸ‰

You've successfully completed:
- âœ… Weeks 1-4 (Foundations, Frameworks, APIs, DevOps)
- âœ… Day 21 (Advanced Integration Testing)
- ğŸ”œ Week 5 Days 2-3 (Performance & Advanced Frameworks)

---

*Last Updated: December 13, 2025*  
*Day 22 Complete Guide v1.0*  
*Week 5 Day 3 - Performance Testing & Load Testing*  
*Master-level Performance Optimization for Enterprise Automation*
