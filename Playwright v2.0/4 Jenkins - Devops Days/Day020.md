# Day 20: Docker Fundamentals for QA Automation

**Date:** Day 20 of 25  
**Duration:** 8 hours  
**Difficulty:** Intermediate-Advanced  
**Focus Area:** Docker Essentials, Container Management, Test Environment Orchestration, Docker Networking & Best Practices  

---

## ðŸŽ¯ **Learning Objectives**

By the end of Day 20, you will:

âœ… Master core Docker concepts and architecture  
âœ… Create optimized Dockerfiles for test automation  
âœ… Build and manage Docker images efficiently  
âœ… Run and orchestrate containers  
âœ… Implement Docker volumes for persistent storage  
âœ… Configure Docker networking for container communication  
âœ… Use Docker Compose for multi-service test environments  
âœ… Integrate Docker with CI/CD pipelines  
âœ… Troubleshoot common Docker issues  
âœ… Build production-ready containerized test infrastructure  

---

## â° **Daily Schedule (8 Hours)**

| Time | Activity | Duration |
|------|----------|----------|
| 8:00 - 8:30 | Review Day 19 & Docker Introduction | 30 min |
| 8:30 - 10:30 | **Theory Session 1:** Docker Architecture & Concepts | 2 hours |
| 10:30 - 11:00 | Break | 30 min |
| 11:00 - 1:00 PM | **Hands-On Lab 1:** Building Docker Images for Testing | 2 hours |
| 1:00 - 2:00 PM | Lunch break | 1 hour |
| 2:00 - 4:00 PM | **Theory Session 2:** Docker Compose & Multi-Service Testing | 2 hours |
| 4:00 - 4:30 PM | Break | 30 min |
| 4:30 - 6:30 PM | **Hands-On Lab 2:** Complete Test Automation Stack | 2 hours |

---

## ðŸ“š **THEORY SESSION 1: Docker Architecture & Concepts (2 hours)**

### **Part 20.1: Understanding Containerization**

#### **What is Docker?**

Docker is a containerization platform that packages applications with all dependencies into isolated containers. Unlike virtual machines, containers share the host OS kernel, making them lightweight and fast.

**Problem Docker Solves:**
```
Traditional Approach:
Source Code â†’ Build â†’ Deploy to Server
Problem: "Works on my machine" - environment inconsistencies

Docker Approach:
Source Code + Dependencies + Config â†’ Container Image â†’ Run anywhere
Solution: Consistent environment across dev, test, and production
```

#### **Key Docker Concepts**

| Concept | Definition | Example |
|---------|-----------|---------|
| **Container** | Lightweight, isolated environment for running applications | Running Python test suite in isolated environment |
| **Image** | Immutable template/blueprint for creating containers | Python 3.11 + pytest + test dependencies |
| **Dockerfile** | Instructions to build a Docker image | Text file with `FROM`, `RUN`, `COPY` commands |
| **Registry** | Repository storing Docker images | Docker Hub, AWS ECR, private registries |
| **Layer** | Read-only filesystem component of an image | Base OS layer, Python layer, dependencies layer |
| **Volume** | Persistent storage for container data | Database files, test reports |
| **Network** | Communication channel between containers | Container-to-container communication |

#### **Docker vs. Virtual Machines**

| Aspect | Docker Container | Virtual Machine |
|--------|------------------|-----------------|
| **Size** | 10-100 MB | 1-10 GB |
| **Boot Time** | Milliseconds to seconds | Minutes |
| **Resource Overhead** | Minimal (shares OS kernel) | High (full OS) |
| **Isolation Level** | Process-level | Full OS-level |
| **Performance** | Near-native | Slower |
| **Use Case** | Microservices, CI/CD, testing | Legacy applications, full isolation |
| **Portability** | Highly portable | Less portable |

### **Part 20.2: Docker Architecture**

#### **Docker Architecture Components**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Client                        â”‚
â”‚    (docker CLI, Docker Desktop UI)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Docker Daemon (dockerd)                â”‚
â”‚                                              â”‚
â”‚  â”œâ”€ Container Runtime (containerd)           â”‚
â”‚  â”œâ”€ Image Manager                            â”‚
â”‚  â”œâ”€ Network Manager                          â”‚
â”‚  â”œâ”€ Storage Driver (overlay2)                â”‚
â”‚  â””â”€ Plugin Manager                           â”‚
â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Registry â”‚            â”‚ Storage  â”‚
    â”‚Docker Hubâ”‚            â”‚ Volumes  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Container Lifecycle**

```
Created
  â†“
Running â†’ Paused â†’ Running
  â†“                   â†“
Stopped â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
Removed
```

#### **Image Layers**

```
Image: ubuntu:22.04 + Python 3.11 + pytest + Code

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 5: Application Code       â”‚ (Changeable)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 4: Test Dependencies      â”‚ (RUN pip install)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3: Python 3.11 Binary     â”‚ (FROM python:3.11)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 2: Ubuntu Packages        â”‚ (System libs)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 1: Base OS (Ubuntu 22.04) â”‚ (Read-only)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Concept: Each layer is cached independently
- Rebuild only affected layers
- Reuse base layers across images
```

### **Part 20.3: Docker Installation & Setup**

#### **Installation on Linux (Ubuntu/Debian)**

```bash
# Step 1: Remove old Docker versions
sudo apt-get remove docker docker-engine docker.io containerd runc

# Step 2: Update package index
sudo apt-get update

# Step 3: Install dependencies
sudo apt-get install -y \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

# Step 4: Add Docker GPG key
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \
    sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Step 5: Set up Docker repository
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] \
  https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Step 6: Install Docker Engine
sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# Step 7: Add current user to docker group
sudo usermod -aG docker $USER
newgrp docker

# Step 8: Verify installation
docker --version
docker run hello-world
```

#### **Installation on macOS**

```bash
# Via Homebrew (recommended)
brew install docker
brew install docker-compose

# Or via DMG installer
# Download from https://www.docker.com/products/docker-desktop
# Run Docker.dmg and follow installation steps

# Verify
docker --version
docker run hello-world
```

#### **Installation on Windows (WSL2)**

```powershell
# Via Chocolatey
choco install docker-desktop

# Or via Windows Package Manager
winget install Docker.DockerDesktop

# Enable WSL2 (via Settings or PowerShell)
wsl --install -d Ubuntu-22.04

# Start Docker Desktop
# Verify
docker --version
docker run hello-world
```

### **Part 20.4: Core Docker Commands**

#### **Image Management**

```bash
# List all images
docker images
docker images -a

# Pull image from registry
docker pull python:3.11
docker pull ubuntu:22.04

# Build image from Dockerfile
docker build -t my-test-image:1.0 .
docker build -f Dockerfile.test -t test-automation:latest .
docker build -t my-image:1.0 --target production .

# Tag image
docker tag my-image:1.0 myregistry/my-image:1.0

# Push to registry
docker push myregistry/my-image:1.0

# Remove image
docker rmi my-image:1.0

# Remove all unused images
docker image prune -a

# Search images
docker search python
docker search selenium

# View image details
docker inspect my-image:1.0
docker history my-image:1.0
```

#### **Container Management**

```bash
# Run container
docker run -d -p 8080:8080 --name my-container python:3.11

# List containers (running)
docker ps

# List all containers
docker ps -a

# View container logs
docker logs my-container
docker logs -f my-container           # Follow logs
docker logs --tail 100 my-container   # Last 100 lines
docker logs -t my-container           # With timestamps

# Execute command in running container
docker exec -it my-container bash
docker exec my-container pytest tests/

# Start stopped container
docker start my-container

# Stop running container
docker stop my-container

# Restart container
docker restart my-container

# Remove container
docker rm my-container

# View container resource usage
docker stats my-container

# Inspect container
docker inspect my-container

# Copy files from/to container
docker cp my-container:/app/report.html ./reports/
docker cp ./tests/ my-container:/app/tests/
```

#### **Useful Run Flags**

```bash
docker run \
    -d \                              # Detach (background)
    -it \                             # Interactive + TTY
    -p 8080:8080 \                    # Port mapping
    -e API_KEY=secret \               # Environment variable
    -v /host:/container \             # Volume mount
    --name my-container \             # Container name
    --memory 512m \                   # Memory limit
    --cpus 1.5 \                      # CPU limit
    --restart=always \                # Restart policy
    --network my-network \            # Custom network
    --health-cmd="curl localhost" \   # Health check
    python:3.11 \                     # Image
    pytest tests/                     # Command
```

### **Part 20.5: Dockerfile Essentials**

#### **Dockerfile Structure**

```dockerfile
# Choose base image
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Set metadata
LABEL maintainer="your-email@example.com" \
      version="1.0" \
      description="Python test automation container"

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copy files from host
COPY requirements.txt .

# Run commands during build
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1

# Expose ports
EXPOSE 8080 9000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8080')"

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Default command (can be overridden)
CMD ["pytest", "tests/", "-v"]
```

#### **Dockerfile Best Practices**

| Practice | Reason | Example |
|----------|--------|---------|
| **Use specific base image tags** | Reproducible builds | `python:3.11` not `python:latest` |
| **Minimize layers** | Smaller image size | `RUN apt-get update && apt-get install && rm` |
| **Clean up cache** | Reduce image size | `rm -rf /var/lib/apt/lists/*` |
| **Use .dockerignore** | Exclude unnecessary files | Add `.git`, `node_modules`, `__pycache__` |
| **Don't run as root** | Security | Create non-root user |
| **Use non-root user** | Security | `USER appuser` |
| **Add HEALTHCHECK** | Reliability | Monitor container health |
| **Set WORKDIR** | Organization | `WORKDIR /app` |
| **Document with LABEL** | Metadata | LABEL version="1.0" |
| **Use multi-stage builds** | Smaller final image | `FROM ubuntu as builder` |

#### **Optimized Dockerfile Example**

```dockerfile
# Stage 1: Builder
FROM python:3.11-slim AS builder

WORKDIR /build

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Create wheels for dependencies
COPY requirements.txt .
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /build/wheels -r requirements.txt

# Stage 2: Runtime
FROM python:3.11-slim

WORKDIR /app

# Copy wheels from builder
COPY --from=builder /build/wheels /wheels
COPY --from=builder /build/requirements.txt .

# Install wheels
RUN pip install --no-cache /wheels/* && rm -rf /wheels

# Copy application
COPY . .

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Set environment
ENV PYTHONUNBUFFERED=1

# Health check
HEALTHCHECK --interval=30s --timeout=10s CMD python -c "print('OK')"

# Run tests
CMD ["pytest", "tests/", "-v"]
```

### **Part 20.6: Docker Volumes & Networking**

#### **Volumes (Persistent Storage)**

```bash
# Create named volume
docker volume create my-data

# Run container with volume
docker run -v my-data:/app/data my-image

# Bind mount (host directory)
docker run -v $(pwd)/data:/app/data my-image

# Read-only volume
docker run -v my-data:/app/data:ro my-image

# List volumes
docker volume ls

# Remove volume
docker volume rm my-data

# Clean up unused volumes
docker volume prune
```

#### **Networks**

```bash
# Create network
docker network create my-network

# Run container on network
docker run --network my-network --name service1 my-image

# Connect running container to network
docker network connect my-network container-id

# List networks
docker network ls

# Inspect network
docker network inspect my-network

# Remove network
docker network rm my-network
```

#### **Container Communication**

```bash
# Create two containers on same network
docker run --name db --network my-net postgres:15
docker run --name app --network my-net my-app

# Inside app container:
# Can access db via hostname: postgres://db:5432/mydb
# Container names resolve to IP addresses on custom networks
```

---

## ðŸ’» **HANDS-ON LAB 1: Building Docker Images for Testing (2 hours)**

### **Exercise 20.1: Create Test Automation Docker Image**

#### **Step 1: Project Structure**

```bash
mkdir docker-test-automation && cd docker-test-automation
mkdir -p tests src config logs reports
touch Dockerfile requirements.txt .dockerignore README.md
```

#### **Step 2: Create requirements.txt**

```txt
# Core testing
pytest==7.4.0
pytest-html==3.2.0
pytest-json-report==1.5.0
pytest-cov==4.1.0

# HTTP/API testing
requests==2.31.0
httpx==0.24.0
jsonschema==4.19.0

# UI automation (optional)
selenium==4.11.0

# Utilities
python-dotenv==1.0.0
colorlog==6.7.0
pyyaml==6.0
```

#### **Step 3: Create Dockerfile**

```dockerfile
# Multi-stage build for optimization
FROM python:3.11-slim AS builder

WORKDIR /build

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Create wheels
COPY requirements.txt .
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /build/wheels -r requirements.txt

# Runtime stage
FROM python:3.11-slim

WORKDIR /app

# Install runtime dependencies only
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copy wheels from builder
COPY --from=builder /build/wheels /wheels
COPY --from=builder /build/requirements.txt .

# Install wheels
RUN pip install --no-cache /wheels/* && rm -rf /wheels

# Copy application
COPY . .

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONPATH=/app

# Create non-root user
RUN useradd -m -u 1000 testuser && chown -R testuser:testuser /app
USER testuser

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import sys; sys.exit(0)" || exit 1

# Default command
CMD ["pytest", "tests/", "-v", "--tb=short"]
```

#### **Step 4: Create .dockerignore**

```
__pycache__
*.pyc
.pytest_cache
.git
.env
.env.local
.vscode
.idea
*.log
*.egg-info
dist/
build/
.coverage
htmlcov/
reports/
.DS_Store
```

#### **Step 5: Create Sample Tests**

**tests/conftest.py:**

```python
import pytest
import os
from pathlib import Path
from datetime import datetime

@pytest.fixture(scope='session')
def test_config():
    """Test configuration from environment"""
    return {
        'api_url': os.getenv('API_URL', 'https://jsonplaceholder.typicode.com'),
        'timeout': int(os.getenv('TEST_TIMEOUT', '10')),
        'environment': os.getenv('ENVIRONMENT', 'test'),
    }

@pytest.fixture
def test_info(request):
    """Test execution metadata"""
    return {
        'test_name': request.node.name,
        'timestamp': datetime.now().isoformat(),
        'container': os.getenv('CONTAINER_NAME', 'docker'),
    }
```

**tests/test_api_basic.py:**

```python
import pytest
import requests
from datetime import datetime

class TestAPIBasics:
    """Basic API tests"""
    
    def test_api_connectivity(self, test_config):
        """Verify API is reachable"""
        response = requests.get(test_config['api_url'])
        assert response.status_code in [200, 301, 302]
    
    def test_get_posts(self, test_config):
        """Test GET /posts endpoint"""
        response = requests.get(f"{test_config['api_url']}/posts", timeout=5)
        assert response.status_code == 200
        data = response.json()
        assert isinstance(data, list)
        assert len(data) > 0
    
    def test_get_specific_post(self, test_config):
        """Test GET /posts/{id}"""
        response = requests.get(f"{test_config['api_url']}/posts/1")
        assert response.status_code == 200
        post = response.json()
        assert 'id' in post
        assert 'title' in post
        assert post['id'] == 1
    
    def test_response_time(self, test_config, test_info):
        """Verify API response time"""
        import time
        start = time.time()
        response = requests.get(f"{test_config['api_url']}/posts/1")
        duration = time.time() - start
        
        assert response.status_code == 200
        assert duration < test_config['timeout']
    
    @pytest.mark.parametrize("post_id", [1, 2, 3, 4, 5])
    def test_posts_pagination(self, test_config, post_id):
        """Test multiple posts"""
        response = requests.get(f"{test_config['api_url']}/posts/{post_id}")
        assert response.status_code == 200
        assert response.json()['id'] == post_id
```

**tests/test_container_info.py:**

```python
import os
import sys
import pytest

class TestContainerEnvironment:
    """Verify container setup"""
    
    def test_python_version(self):
        """Check Python version"""
        assert sys.version_info.major == 3
        assert sys.version_info.minor >= 11
    
    def test_required_packages(self):
        """Verify required packages"""
        import pytest
        import requests
        import yaml
        assert pytest is not None
        assert requests is not None
    
    def test_environment_variables(self):
        """Check environment variables"""
        pythonpath = os.getenv('PYTHONPATH')
        assert pythonpath == '/app'
    
    def test_working_directory(self):
        """Verify working directory"""
        cwd = os.getcwd()
        assert cwd == '/app'
    
    def test_filesystem_writable(self, tmp_path):
        """Test filesystem write capability"""
        test_file = tmp_path / "test.txt"
        test_file.write_text("test content")
        assert test_file.read_text() == "test content"
```

#### **Step 6: Build Docker Image**

```bash
# Build image
docker build -t test-automation:1.0 .

# Build with build args
docker build \
    --build-arg PYTHON_VERSION=3.11 \
    -t test-automation:latest .

# View build layers
docker history test-automation:1.0

# Check image size
docker images | grep test-automation

# Typical output:
# test-automation   1.0        abc123def456   2 minutes ago   450MB
```

#### **Step 7: Run Tests in Container**

```bash
# Run all tests
docker run --rm test-automation:1.0

# Run with environment variables
docker run --rm \
    -e API_URL=https://jsonplaceholder.typicode.com \
    -e ENVIRONMENT=production \
    test-automation:1.0

# Run specific test
docker run --rm \
    test-automation:1.0 \
    pytest tests/test_container_info.py -v

# Run with volume mount (test code)
docker run --rm \
    -v $(pwd)/tests:/app/tests \
    test-automation:1.0

# Run with report output
docker run --rm \
    -v $(pwd)/reports:/app/reports \
    test-automation:1.0 \
    pytest tests/ --html=reports/report.html

# Interactive shell
docker run -it --rm test-automation:1.0 /bin/bash
```

#### **Step 8: Verify Image**

```bash
# Check image details
docker inspect test-automation:1.0 | grep -i size

# Check layers
docker history test-automation:1.0

# Test image locally
docker run --rm test-automation:1.0 python --version

# Get into container
docker run -it --rm test-automation:1.0 bash
# Inside container:
# python --version
# pip list
# pytest tests/ -v
# exit
```

### **Exercise 20.2: Optimize Docker Image**

**Goals:**
1. Reduce image size
2. Use multi-stage builds
3. Cache layers efficiently
4. Remove unnecessary files

```dockerfile
# Optimized Dockerfile
FROM python:3.11-slim AS dependencies

WORKDIR /build
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential gcc \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /wheels -r requirements.txt

# =========================================

FROM python:3.11-slim

WORKDIR /app

# Copy only wheels
COPY --from=dependencies /wheels /wheels
COPY --from=dependencies /build/requirements.txt .

RUN pip install --no-cache /wheels/* && rm -rf /wheels /tmp/*

# Only copy necessary files
COPY tests/ tests/
COPY pytest.ini .
COPY README.md .

ENV PYTHONUNBUFFERED=1 PYTHONDONTWRITEBYTECODE=1

RUN useradd -m -u 1000 testuser && chown -R testuser:testuser /app
USER testuser

HEALTHCHECK CMD python -c "print('OK')" || exit 1

CMD ["pytest", "tests/", "-v"]
```

**Compare sizes:**

```bash
# Build both versions
docker build -t test-automation:basic -f Dockerfile.basic .
docker build -t test-automation:optimized -f Dockerfile.optimized .

# Check sizes
docker images | grep test-automation

# Typical results:
# test-automation  optimized   abc123...   2 min ago   380MB
# test-automation  basic       def456...   5 min ago   650MB
# Savings: ~42% reduction
```

---

## ðŸ“š **THEORY SESSION 2: Docker Compose & Multi-Service Testing (2 hours)**

### **Part 20.7: Docker Compose Fundamentals**

#### **What is Docker Compose?**

Docker Compose is a tool for defining and running multi-container Docker applications using a YAML file.

**Benefits:**
- Define entire application in single YAML file
- Start/stop all services with one command
- Automatic networking between services
- Environment variable management
- Volume management
- Service dependencies

#### **docker-compose.yml Syntax**

```yaml
version: '3.8'  # Compatible with Docker 19.03+

services:
  service-name:
    image: image-name:tag           # Or build: ./path
    container_name: name            # Custom container name
    ports:                          # Port mapping
      - "8080:8080"
    environment:                    # Environment variables
      - VAR_NAME=value
      - API_URL=${API_URL}
    volumes:                        # Storage mounts
      - volume-name:/container/path
      - ./host/path:/container/path
    networks:                       # Network assignment
      - network-name
    depends_on:                     # Service dependencies
      - service-name
    healthcheck:                    # Health monitoring
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart_policy:                 # Auto-restart
      condition: on-failure
      max_attempts: 3
    environment_file:               # Load from file
      - .env.test

volumes:
  volume-name:                      # Named volume definition
    driver: local

networks:
  network-name:                     # Network definition
    driver: bridge
```

### **Part 20.8: Production Docker Compose Setup**

#### **Complete Test Automation Stack**

**docker-compose.yml:**

```yaml
version: '3.8'

services:
  # Database service
  postgres:
    image: postgres:15-alpine
    container_name: test-db
    environment:
      POSTGRES_USER: testuser
      POSTGRES_PASSWORD: testpass
      POSTGRES_DB: testdb
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U testuser"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - test-network

  # Redis cache
  redis:
    image: redis:7-alpine
    container_name: test-cache
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - test-network

  # API server
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: test-api
    environment:
      DB_HOST: postgres
      DB_USER: testuser
      DB_PASSWORD: testpass
      DB_NAME: testdb
      REDIS_HOST: redis
      REDIS_PORT: 6379
    ports:
      - "8080:8080"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - test-network

  # Test runner
  test-runner:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: automation-tests
    environment:
      API_URL: http://api:8080
      DB_HOST: postgres
      DB_USER: testuser
      DB_PASSWORD: testpass
      DB_NAME: testdb
      ENVIRONMENT: docker-compose
    volumes:
      - ./tests:/app/tests
      - ./reports:/app/reports
      - ./logs:/app/logs
    depends_on:
      api:
        condition: service_healthy
    networks:
      - test-network
    command: pytest tests/ -v --html=reports/report.html

volumes:
  postgres_data:

networks:
  test-network:
    driver: bridge
```

#### **Docker Compose Commands**

```bash
# Start all services
docker-compose up
docker-compose up -d              # Detached

# Stop services
docker-compose stop
docker-compose down               # Stop and remove containers
docker-compose down -v            # Also remove volumes

# View logs
docker-compose logs
docker-compose logs -f api        # Follow service logs
docker-compose logs --tail 50     # Last 50 lines

# Execute commands
docker-compose exec api bash
docker-compose exec test-runner pytest tests/ -v

# Build services
docker-compose build
docker-compose build --no-cache

# View service status
docker-compose ps
docker-compose top api            # View processes

# Restart services
docker-compose restart
docker-compose restart api        # Restart specific service

# Push to registry
docker-compose push               # Push all images
```

---

## ðŸ’» **HANDS-ON LAB 2: Complete Test Automation Stack (2 hours)**

### **Exercise 20.3: Build Multi-Service Test Environment**

#### **Step 1: Project Structure**

```bash
mkdir docker-compose-automation && cd docker-compose-automation

mkdir -p \
    api/src \
    tests \
    config \
    reports \
    logs \
    init-db

# Create files
touch docker-compose.yml Dockerfile .env.example .dockerignore README.md
```

#### **Step 2: Create API Dockerfile**

**api/Dockerfile:**

```dockerfile
FROM python:3.11-slim

WORKDIR /app

RUN apt-get update && apt-get install -y --no-install-recommends \
    curl postgresql-client \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY src/ .

ENV FLASK_APP=app.py \
    FLASK_ENV=production \
    PYTHONUNBUFFERED=1

EXPOSE 8080

HEALTHCHECK --interval=10s --timeout=5s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

CMD ["gunicorn", "--bind", "0.0.0.0:8080", "--workers", "2", "app:app"]
```

**api/requirements.txt:**

```txt
Flask==2.3.0
gunicorn==21.0.0
psycopg2-binary==2.9.0
redis==5.0.0
requests==2.31.0
```

**api/src/app.py:**

```python
from flask import Flask, jsonify
import os
import psycopg2

app = Flask(__name__)

@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({'status': 'healthy'}), 200

@app.route('/api/test', methods=['GET'])
def get_test():
    """Sample API endpoint"""
    return jsonify({
        'message': 'Test API working',
        'environment': os.getenv('FLASK_ENV')
    }), 200

@app.route('/api/db-check', methods=['GET'])
def db_check():
    """Check database connection"""
    try:
        db_host = os.getenv('DB_HOST', 'localhost')
        db_user = os.getenv('DB_USER', 'postgres')
        db_password = os.getenv('DB_PASSWORD', '')
        db_name = os.getenv('DB_NAME', 'postgres')
        
        conn = psycopg2.connect(
            host=db_host,
            user=db_user,
            password=db_password,
            database=db_name
        )
        conn.close()
        return jsonify({'database': 'connected'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080, debug=False)
```

#### **Step 3: Create docker-compose.yml**

**docker-compose.yml:**

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: test-postgres
    environment:
      POSTGRES_USER: ${DB_USER:-testuser}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-testpass}
      POSTGRES_DB: ${DB_NAME:-testdb}
    ports:
      - "${DB_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-testuser}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network

  redis:
    image: redis:7-alpine
    container_name: test-redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: test-api
    environment:
      DB_HOST: postgres
      DB_USER: ${DB_USER:-testuser}
      DB_PASSWORD: ${DB_PASSWORD:-testpass}
      DB_NAME: ${DB_NAME:-testdb}
      REDIS_HOST: redis
      FLASK_ENV: production
    ports:
      - "8080:8080"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - app-network

  test-runner:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: test-automation
    environment:
      API_URL: http://api:8080
      DB_HOST: postgres
      DB_USER: ${DB_USER:-testuser}
      DB_PASSWORD: ${DB_PASSWORD:-testpass}
      DB_NAME: ${DB_NAME:-testdb}
      ENVIRONMENT: docker-compose
    volumes:
      - ./tests:/app/tests
      - ./reports:/app/reports
      - ./logs:/app/logs
    depends_on:
      api:
        condition: service_healthy
    networks:
      - app-network
    command: pytest tests/ -v --html=reports/report.html

volumes:
  postgres_data:

networks:
  app-network:
    driver: bridge
```

#### **Step 4: Create Environment File**

**.env.example:**

```env
# Database Configuration
DB_USER=testuser
DB_PASSWORD=testpass
DB_NAME=testdb
DB_PORT=5432

# API Configuration
API_HOST=0.0.0.0
API_PORT=8080

# Test Configuration
TEST_TIMEOUT=30
ENVIRONMENT=docker-compose

# Logging
LOG_LEVEL=INFO
```

**Create .env from .env.example:**

```bash
cp .env.example .env
```

#### **Step 5: Create Comprehensive Tests**

**tests/test_docker_stack.py:**

```python
import pytest
import requests
import os
from datetime import datetime

class TestAPIStack:
    """Test complete API stack"""
    
    @pytest.fixture(autouse=True)
    def setup(self):
        """Setup test environment"""
        self.api_url = os.getenv('API_URL', 'http://localhost:8080')
        self.timeout = int(os.getenv('TEST_TIMEOUT', '10'))
    
    def test_api_health(self):
        """Verify API is running"""
        response = requests.get(
            f"{self.api_url}/health",
            timeout=self.timeout
        )
        assert response.status_code == 200
        assert response.json()['status'] == 'healthy'
    
    def test_api_endpoint(self):
        """Test sample API endpoint"""
        response = requests.get(
            f"{self.api_url}/api/test",
            timeout=self.timeout
        )
        assert response.status_code == 200
        data = response.json()
        assert 'message' in data
        assert 'environment' in data
    
    def test_database_connection(self):
        """Verify database is accessible"""
        response = requests.get(
            f"{self.api_url}/api/db-check",
            timeout=self.timeout
        )
        assert response.status_code == 200
        assert 'database' in response.json()

class TestDockerEnvironment:
    """Test Docker environment setup"""
    
    def test_container_environment(self):
        """Verify container environment"""
        api_url = os.getenv('API_URL')
        db_host = os.getenv('DB_HOST')
        
        assert api_url is not None
        assert db_host is not None
        assert db_host == 'postgres'
    
    def test_imports(self):
        """Verify required packages"""
        import pytest
        import requests
        assert pytest and requests
    
    def test_timestamps(self):
        """Verify time functions"""
        timestamp = datetime.now().isoformat()
        assert 'T' in timestamp
```

#### **Step 6: Run Docker Compose Stack**

```bash
# Start all services
docker-compose up -d

# Wait for services to be healthy
sleep 10

# Check service status
docker-compose ps

# View logs
docker-compose logs

# Run tests
docker-compose run test-runner

# Or execute in running container
docker-compose exec test-runner pytest tests/ -v

# Stop services
docker-compose down

# Clean up volumes
docker-compose down -v
```

#### **Step 7: Create Makefile for Convenience**

**Makefile:**

```makefile
.PHONY: help build up down logs test clean

help:
	@echo "Available commands:"
	@echo "  make build      - Build Docker images"
	@echo "  make up         - Start all services"
	@echo "  make down       - Stop all services"
	@echo "  make logs       - View service logs"
	@echo "  make test       - Run tests"
	@echo "  make clean      - Remove containers and volumes"

build:
	docker-compose build

up:
	docker-compose up -d
	sleep 5
	docker-compose ps

down:
	docker-compose down

logs:
	docker-compose logs -f

test:
	docker-compose exec test-runner pytest tests/ -v

clean:
	docker-compose down -v
	docker rmi $$(docker images -q)
```

**Usage:**

```bash
make build
make up
make test
make logs
make clean
```

---

## ðŸ§ª **Quiz - Docker Fundamentals (10 Questions)**

**Question 1:** What is the main advantage of containers over virtual machines?
- A) More features
- B) Larger size
- C) Lightweight and shared OS kernel
- D) Better for legacy apps
**Answer: C** - Containers are lightweight and share the host OS kernel

**Question 2:** Which command builds a Docker image?
- A) `docker run`
- B) `docker build`
- C) `docker create`
- D) `docker compile`
**Answer: B** - `docker build` creates images from Dockerfile

**Question 3:** What does `-d` flag do in `docker run`?
- A) Delete container
- B) Detach (run in background)
- C) Debug mode
- D) Default settings
**Answer: B** - `-d` runs container in detached mode

**Question 4:** Which line in Dockerfile specifies base image?
- A) BASE
- B) IMPORT
- C) FROM
- D) USE
**Answer: C** - `FROM` specifies the base image

**Question 5:** What is a Docker volume used for?
- A) Code storage
- B) Persistent data storage
- C) Network configuration
- D) Image metadata
**Answer: B** - Volumes provide persistent storage

**Question 6:** Which command lists all running containers?
- A) `docker list`
- B) `docker ps`
- C) `docker containers`
- D) `docker show`
**Answer: B** - `docker ps` lists running containers

**Question 7:** What does Docker Compose primarily do?
- A) Compile Docker images
- B) Define and run multi-container applications
- C) Push images to registry
- D) Delete unused containers
**Answer: B** - Docker Compose manages multi-container applications

**Question 8:** Which file defines services for Docker Compose?
- A) `docker.yml`
- B) `services.yaml`
- C) `docker-compose.yml`
- D) `containers.yml`
**Answer: C** - `docker-compose.yml` defines services

**Question 9:** What is a healthcheck in Docker?
- A) Virus scan
- B) Container monitoring mechanism
- C) Backup system
- D) Performance optimizer
**Answer: B** - Healthchecks monitor container status

**Question 10:** Which best practice creates smaller images?
- A) Use latest base images
- B) Copy all files
- C) Multi-stage builds
- D) Keep all dependencies
**Answer: C** - Multi-stage builds optimize image size

---

## ðŸ’¼ **Mini-Assignment 20.1: Build Production-Ready Test Container**

**Objective:** Create optimized Docker image for test automation

**Requirements:**
1. Multi-stage Dockerfile
2. Non-root user
3. Health check
4. Environment variables
5. Volume support
6. Test execution
7. Report generation

**Deliverables:**
- [ ] Optimized Dockerfile
- [ ] .dockerignore file
- [ ] Test suite (minimum 10 tests)
- [ ] Build script
- [ ] Image size < 500MB
- [ ] Successful test execution
- [ ] Documentation

**Submission:**
```bash
# Build image
docker build -t my-test-automation:1.0 .

# Run tests
docker run --rm \
    -v $(pwd)/reports:/app/reports \
    my-test-automation:1.0

# Check image size
docker images | grep my-test-automation
```

---

## ðŸ’¼ **Mini-Assignment 20.2: Multi-Service Docker Compose Setup**

**Objective:** Create complete test automation stack with multiple services

**Requirements:**
1. Database service (PostgreSQL)
2. Cache service (Redis)
3. API service
4. Test runner service
5. Environment configuration
6. Health checks
7. Volume management
8. Network configuration

**Deliverables:**
- [ ] docker-compose.yml
- [ ] .env configuration
- [ ] API Dockerfile
- [ ] Test Dockerfile
- [ ] Comprehensive test suite
- [ ] Integration tests
- [ ] Documentation

**Submission:**
```bash
# Start stack
docker-compose up -d

# Run tests
docker-compose exec test-runner pytest tests/ -v

# Verify services
docker-compose ps
```

---

## ðŸ“‹ **Daily Checklist - Day 20**

- [ ] Reviewed Day 19 Cypress fundamentals
- [ ] Understood Docker containerization concepts
- [ ] Completed Theory Session 1 (Architecture & Concepts)
- [ ] Installed Docker on system
- [ ] Learned Docker core commands
- [ ] Completed Exercise 20.1 (Build test image)
- [ ] Verified Docker image execution
- [ ] Completed Theory Session 2 (Docker Compose)
- [ ] Created docker-compose.yml
- [ ] Built multi-service stack
- [ ] Completed Exercise 20.2 (Optimize image)
- [ ] Completed Exercise 20.3 (Multi-service setup)
- [ ] Answered 10 quiz questions
- [ ] Achieved 80%+ quiz score (8/10)
- [ ] Completed Mini-Assignment 20.1
- [ ] Completed Mini-Assignment 20.2
- [ ] Tested all components
- [ ] Pushed to GitHub
- [ ] Documented setup process
- [ ] Updated learning journal

**Daily Metrics:**
- Quiz Score: ___/10
- Docker images created: ___ count
- Test containers built: ___ count
- Docker Compose services: ___ count
- Image optimization: ___% reduction
- Confidence Level (1-5): ___
- Time Spent: ___ hours
- Challenges Faced: _________________

---

## ðŸŽ¯ **Key Takeaways from Day 20**

1. **Containerization solves environment inconsistencies** - Same setup everywhere
2. **Docker is lightweight compared to VMs** - Resource-efficient testing
3. **Multi-stage builds significantly reduce image size** - Smaller deployments
4. **Docker Compose simplifies multi-service testing** - Orchestration made easy
5. **Health checks ensure service readiness** - Reliable test environments
6. **Non-root users improve security** - Best practice for production
7. **Volume management enables data persistence** - Important for databases
8. **Environment variables configure flexibility** - Different environments easily
9. **Networking connects containers seamlessly** - Service communication
10. **Docker is essential for modern DevOps** - Industry standard skill

---

## ðŸ”— **Resources for Further Learning**

- [Docker Official Documentation](https://docs.docker.com/)
- [Docker Best Practices Guide](https://docs.docker.com/develop/dev-best-practices/)
- [Docker Compose Reference](https://docs.docker.com/compose/compose-file/)
- [Dockerfile Best Practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)
- [Docker Hub Registry](https://hub.docker.com/)

---

## ðŸš€ **Ready for Day 21?**

By completing Day 20, you've mastered:
- âœ… Docker containerization fundamentals
- âœ… Dockerfile creation and optimization
- âœ… Multi-stage builds
- âœ… Container management
- âœ… Docker volumes and networking
- âœ… Docker Compose orchestration
- âœ… Multi-service testing environments
- âœ… Production-ready configurations
- âœ… Security best practices
- âœ… CI/CD integration readiness

**Next (Day 21):** Advanced Integration & Mock Testing

---

## ðŸ“Š **Course Progress**

```
Week 1          Week 2          Week 3          Week 4          Week 5
Foundation      Mastery         API Testing     DevOps          Advanced
Days 1-5        Days 6-11       Days 12-15      Days 16-20      Days 21-25
âœ… 100%         âœ… 100%         âœ… 100%         ðŸ”œ Day 20       ðŸ”œ Final
                                               (80%)            Weeks

Overall: 20/25 Days Complete (80%)
```

---

**Congratulations on reaching Day 20!** ðŸŽ‰

You're 80% through the intensive Automation Test Engineer Upskilling Program!

---

*Last Updated: December 13, 2025*  
*Day 20 Complete Guide v1.0*  
*Week 4 Day 5 - Docker Fundamentals for QA*  
*Master-level Containerization for Test Automation*